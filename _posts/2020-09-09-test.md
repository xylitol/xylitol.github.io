---
title:  "AlexNet paper review"
last_modified_at: 2020-12-18 15:59:00 -0400
categories: 
  - Deep Learning paper review
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# ImageNet Classification with Deep Convolutional Neural Networks
> Alex Krizhevsky, et al. ["ImageNet Classification with Deep Convolutional Neural Networks"](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) 2012.

# Abstract
해당 논문의 모델로 ImageNet LSVRC-2010 대회에서 테스트 데이터에 대해 기존의 어느 모델보다 정확도가 가장 높은 top-1 에러가 37.5% 이고 top-5 에러는 17.0%를 달성했습니다.

# Introduction
object 인식에 딥러닝은 필수적이지만 많은 데이터셋을 필요로 한다. 최근이 되어서야 ImageNet, Labelme와 같은 데이터셋이 생겨났다.
데이터셋은 많아진다고 object 인식이 잘되는 것만은 아니다. 우리는 우리가 가지지 않은 데이터를 충당하기 위한 사전지식을 가지고 있어야 한다. 그래서 많은 모델에서 CNN을 사용하고 있다. CNN은 수용 능력이 크고 자연 이미지에 강력하다. feed forward NN과 비교 했을 때 더 적은 연결과 파라미터만 필요로 하고 더 쉽게 학습된다.
CNN은 계산량이 많지만 최근의 GPU로 이를 해결할 수 있다.
우리의 Network는 5개의 Conv Layer와 3개의 FC Layer로 이루어져 있다.

# The Dataset
우리 시스템은 입력으로 고정된 차원의 데이터를 필요하여 ImageNet의 이미지를 256*256 사이즈로 DownSampling 하여 사용한다. 그리고 학습셋을 평균값으로 빼주는 것 외의 전처리는 하지 않았다.

# The Architecture
뉴런의 output 함수로 tanh(x)나 sigmoid함수를 사용하는 것보다 ReLU함수를 이용하는게 훨씬 빠르다. ReLU함수를 이용하면 기존의 output함수보다 적은 학습 횟수로도 같은 error rate를 달성할 수 있다. Jarett에서는 |tanh(x)| 함수를 사용했는데 이는 오버피팅 방지 목적이었고, 우리는 학습시간을 단축시키기 위함이기에 다른 효과이다.
<p align="center">
  <img src="/assets/img/paper_review/AlexNet/fig1.png" width="40%" height="40%" title="70px" alt="memoryblock">
</p>
위 그래프는 ReLU함수(실선)를 사용하였을 때와 tanh함수(점선)을 사용하였을 때의 epoch에 따른 error rate를 나타낸다.

ReLU는 saturating 되지 않게 하기 위해 입력을 정규화 시켜줄 필요가 없다. 그럼에도 정규화를 하면 일반화에 도움을 주어 더 나은 성능을 보여준다.

전통적으로 pooling을 할 때 겹치지 않게 하였지만 우리는 오버피팅을 줄이기 위해 오버래핑 풀링을 하였다.
<p align="center">
  <img src="/assets/img/paper_review/AlexNet/fig2.png" width="60%" height="60%" title="70px" alt="memoryblock">
</p>
전체적인 구조는 5개의 Conv Layer, 3개의 FC Layer가 포함되어 있다. 마지막 FC Layer의 출력은 1000개의 softmax로 들어간다.
1,2번째 Conv Layer에는 Response-normalization과 Max-Pooling이 같이 들어가 있고, 5번째 Conv Layer에는 Max-Pooling만 들어있다. ReLU Layer는 모든 Conv Layer와 FC Layer의 출력 다음에 적용한다.
Figure 2에서 위, 아래의 층은 2개의 GPU가 각각 수행한다.

# Reducing Overfitting
오버피팅을 줄이기 위한 방법들이다.
데이터 셋을 증가 시키는데 기존의 이미지에서 약간만 변형시켜 새로운 이미지를 얻는다. 변형시키는 방법으로는 두가지를 사용하였다. ⓵이미지 이동, 수평 뒤집기 ⓶RGB 값 조절

Dropout 방법을 통해서도 Overfitting을 줄인다. Dropout은 히든 뉴런들 50%의 출력을 0으로 설정하여 Dropout된 뉴런들이 forward pass나 back propagation 과정에 관여하지 않게 한다. Dropout은 1,2번째 FC Layer에서 적용한다.

# Result
<p align="center">
  <img src="/assets/img/paper_review/AlexNet/fig3.png" width="40%" height="40%" title="70px" alt="memoryblock"><br>
  ILSVRC-2010 test set에서 다른 모델들과 비교하였을 때 성능차이
</p>

<p align="center">
  <img src="/assets/img/paper_review/AlexNet/fig4.png" width="40%" height="40%" title="70px" alt="memoryblock">
</p>
ILSVRC-2012 validation과 test set에서 다른 모델과 다양한 모델을 비교하였을 때 error rate <br>

<p align="center">
  <img src="/assets/img/paper_review/AlexNet/fig5.png" width="40%" height="40%" title="70px" alt="memoryblock">
</p>
ILSVRC-2010의 test image 중 8개를 해당 논문의 모델이 예측한 확률이다.


















