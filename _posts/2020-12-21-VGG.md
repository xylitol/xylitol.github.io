---
title:  "VGG paper review"
last_modified_at: 2020-12-21 14:44:00 -0400
categories: 
  - Deep Learning paper review
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# ImageNet Classification with Deep Convolutional Neural Networks
> Karen Simonyan, Andrew Zisserman ["Very Deep Convolutional Networks for Large-Scale Image Recognition"](https://arxiv.org/abs/1409.1556) 2015.

# Abstract
이 논문에서는 convolution network의 깊이가 정확도에 끼치는 영향에 대해 조사하였다. 3*3 크기의 convolution 필터를 사용하였고, 16~19층의 깊이에서 상당한 정확도 향상을 보였다. 이를 통해 ImageNet Challenge 2014의 lacalization, classification에서 각각 1위와 2위를 하였다.

# Convnet Configuration
Network 구조에서 입력 사이즈는 224*224의 고정 사이즈로 받고 전처리 과정은 평균 RGB값은 빼주는 것만 있다. 필터는 3*3 필터, 1*1 필터만 사용하고 stride는 1, 3*3 필터의 Conv Layer에서 padding은 1로 고정한다.
3*3 필터를 사용하는 것은 기존의 Network 보다 작은 필터를 사용하는 것인데 이렇게 하면 큰 필터를 한번 사용하는 것보다 층이 더 깊어지고 non-linear recification Layer가 많아진다. 무엇보다도 파라미터의 수를 줄일 수 있게 된다. 그리고 1*1 필터를 사용하는 Conv Layer는 필터의 영향은 덜 받게 되고 비선형성이 증가한다.
<p align="center">
  <img src="/assets/img/paper_review/VGG/fig1.JPG" width="60%" height="60%" title="70px" alt="memoryblock">
</p>

# Classification Framework
학습과정에서는 mini-batch를 적용하고 dropout을 처음 두 개의 FC Layer에 적용시킨다. Learning Rate는 0.01로 초기화하고 정확도가 향상되지 않을 때마다 10배 감소시켰다. 74 epoch을 적용시켰는데 이는 AlexNet보다 적은 epoch이다. 이렇게 할 수 있었던 이유는 층의 깊이가 깊고 작은 사이즈의 필터(3*3)을 사용하고, 미리 학습된 층을 이용하여 초기화 하였기 때문이다.
가중치 초기화는 랜덤한 초기화로 충분한 얕은 Network(11개의 층)를 학습시키고 그 값을 이용하여 첫 네 개의 Conv Layer와 마지막 3개의 FC Layer를 초기화한다.
입력 이미지로는 사이즈를 조정한 이미지에서 랜덤하게 crop한 이미지를 사용하거나 AlexNet과 마찬가지로 수평하게 뒤집거나 RGB에 변화를 주었다.

# Classification Experiments
<p align="center">
  <img src="/assets/img/paper_review/VGG/fig2.JPG" width="60%" height="60%" title="70px" alt="memoryblock">
  <img src="/assets/img/paper_review/VGG/fig3.JPG" width="60%" height="60%" title="70px" alt="memoryblock">
  <img src="/assets/img/paper_review/VGG/fig4.JPG" width="60%" height="60%" title="70px" alt="memoryblock">
</p>

# Conclusion
2014 ILSVRC에서 top-5 error 7.3%를 기록하였다. 이를 통해 네트워크의 깊이가 깊어질수록 이미지 분류 정확도가 높아지는 것이 증명 되었다.
