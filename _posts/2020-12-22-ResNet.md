---
title:  "ResNet paper review"
last_modified_at: 2020-12-22 12:10:00 -0400
categories: 
  - Deep Learning paper review
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# Deep Residual Learning for Image Recognition
> Kaiming He, et al. ["Deep Residual Learning for Image Recognition"](https://arxiv.org/abs/1512.03385) Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.   
<br>
<br>
<br>
<br>
<br>
<br>


CNN에서 깊이가 깊어질수록 성능이 계속 증가할 것 같지만 정확도가 포화상태에 도달하게 되면 성능이 떨어지는 현상이 나타난다. 이는 overfitting으로 인한 문제가 아니다. 이 문제를 해결하기 위해서  Residual Learning을 사용한다.

<p align="center">
  <img src="/assets/img/paper_review/ResNet/fig1.JPG" width="80%" height="80%" title="70px" alt="memoryblock">
  
  위 그래프는 CIFAR-10을 각각 20-layer, 56-layer network의 train, test error이다.
</p>

<br>
<br>

<p align="center">
  <img src="/assets/img/paper_review/ResNet/fig1-2.JPG" width="50%" height="50%" title="70px" alt="memoryblock">
</p>
위의 그림이 Residual Learning 방법을 도식으로 그려낸 것이다. 이 방식은 추가적인 파라미터나 computational complexity가 추가되지 않는다. 그리고 기존의 common library로 쉽게 구현할 수 있다.
F(x) + x 식을 계산하기 위해서는 둘의 dimension이 같아야 한다 이를 위해 x에 linear projection Ws를 곱해 준다.

실험에 사용된 Network는 Plain Network, Residual Network가 있는데 Plain Network는 VGG Network의 축소판이라고 할 수 있다. Residual Network는 Plain Network를 기반으로 shortcut connection을 삽입한 network이다.
<p align="center">
  <img src="/assets/img/paper_review/ResNet/fig2.JPG" width="60%" height="60%" title="70px" alt="memoryblock">
</p>
위 그림에서 왼쪽은 VGG-19이고, 가운데는 Plain network, 오른쪽은 Residual Network이다. Residual Network에서 점선 shortcut은 x의 dimension을 동일하게 하는게 필요하기 때문에 zero padding을 하거나 1*1 conv를 해준다.

학습은 ImageNet 2012로 진행하였다.   

<p align="center">
  <img src="/assets/img/paper_review/ResNet/fig3.JPG" width="80%" height="80%" title="70px" alt="memoryblock">
</p>
얇은 선은 training error를 두꺼운 선은 validation error를 나타낸다. 왼쪽은 Plain Network, 오른쪽은 Residual Network이다.
Plain Network에서는 34-layer가 18-layer보다 error가 높은 것을 보면 Degradation Problem이라고 할 수 있다. 반면 ResNet에서는 이 문제가 해결된 것을 확인할 수 있다.   

<br>
<br>

<p align="center">
  <img src="/assets/img/paper_review/ResNet/fig4.JPG" width="60%" height="60%" title="70px" alt="memoryblock">
</p>
위 표는 Top-1 error를 비교한 표이다, 마찬가지로 Plain 에서는 degradation problem이 발생하고, ResNet은 해결된 것을 확인할 수 있다.

또한 152-Layer Resnet single model이 top-5 validation error가 4.49%를 기록하였고, 각각의 깊이 6개의 모델과 앙상블한 모델은 top-5 error 3.57%를 기록하였다. 이 기록으로 ILSVRC 2015에서 1위를 달성하였다.
<p align="center">
  층이 많아져 training 시간이 오래 걸리는 것을 줄이기 위하여 Bottlenet 구조를 만들었다. 이 구조는 아래 그림의 왼쪽과 같은 기존의 3*3 필터를 오른쪽과 같은 3층으로 나누었다. 이를 통해 Dimension의 크기를 줄이고 시간 복잡도도 줄이는 효과를 볼 수 있다.
  
  <img src="/assets/img/paper_review/ResNet/fig5.JPG" width="70%" height="70%" title="70px" alt="memoryblock">
</p>

<p align="center">
  <img src="/assets/img/paper_review/ResNet/fig6.JPG" width="50%" height="50%" title="70px" alt="memoryblock">
  
  위 표에서는 층의 개수에 따른 error를 볼 수 있는데 110까지는 error가 낮아지다가 1202 에서는 OverFitting으로 인해 오히려 error가 높아진 것을 볼 수 있다.
</p>
